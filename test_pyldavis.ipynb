{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from AuDoLab import AuDoLab\r\n",
    "\r\n",
    "audo = AuDoLab.AuDoLab()\r\n",
    "print(audo.is_notebook())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "True\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "if __name__ == \"__main__\":\r\n",
    "    # Load target data from reuters dataset\r\n",
    "    from nltk.corpus import reuters\r\n",
    "    import numpy as np\r\n",
    "    import pandas as pd\r\n",
    "\r\n",
    "    data = []\r\n",
    "\r\n",
    "    for fileid in reuters.fileids():\r\n",
    "        tag, filename = fileid.split(\"/\")\r\n",
    "        data.append(\r\n",
    "            (filename,\r\n",
    "                \", \".join(\r\n",
    "                    reuters.categories(fileid)),\r\n",
    "                reuters.raw(fileid)))\r\n",
    "\r\n",
    "    # store loaded data in dataframe\r\n",
    "    data = pd.DataFrame(data, columns=[\"filename\", \"categories\", \"text\"])\r\n",
    "\r\n",
    "    #####------\r\n",
    "    # start using audolab\r\n",
    "\r\n",
    "    # clean theloaded data\r\n",
    "    preprocessed_target = audo.text_cleaning(data=data, column=\"text\")\r\n",
    "\r\n",
    "    # scrape ieee\r\n",
    "    scraped_documents = audo.get_ieee(pages=1)\r\n",
    "\r\n",
    "    # clean the scraped papers\r\n",
    "    preprocessed_paper = audo.text_cleaning(data=scraped_documents, column=\"abstract\")\r\n",
    "\r\n",
    "    # calculate tfidf values on joint corpus\r\n",
    "    target_tfidf, training_tfidf = audo.tf_idf(\r\n",
    "        data=preprocessed_target,\r\n",
    "        papers=preprocessed_paper,\r\n",
    "        data_column=\"lemma\",\r\n",
    "        papers_column=\"lemma\",\r\n",
    "        features=100000,\r\n",
    "    )\r\n",
    "\r\n",
    "    # calculate one_class_svm on data\r\n",
    "    o_svm_result = audo.one_class_svm(\r\n",
    "        training=training_tfidf,\r\n",
    "        predicting=target_tfidf,\r\n",
    "        nus=np.round(np.arange(0.001, 0.5, 0.01), 7),\r\n",
    "        quality_train=0.9,\r\n",
    "        min_pred=0.001,\r\n",
    "        max_pred=0.05,\r\n",
    "    )\r\n",
    "\r\n",
    "    # select a classifier\r\n",
    "    result = audo.choose_classifier(preprocessed_target, o_svm_result, 0)\r\n",
    "\r\n",
    "    # perform topic modeling and plot the created topics\r\n",
    "    lda_target = audo.lda_modeling(data=result, num_topics=5)\r\n",
    "    #audo.lda_visualize_topics(type=\"clouds\", n_clouds=4)\r\n",
    "    audo.lda_visualize_topics(type=\"pyldavis\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 10788/10788 [00:03<00:00, 2848.76it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The algorithm is iterating through 1 pages\n",
      "Total number of abstracts that will be scraped: 100\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 100/100 [00:56<00:00,  1.78it/s]\n",
      "100%|██████████| 93/93 [00:00<00:00, 1500.84it/s]\n",
      "100%|██████████| 93/93 [00:00<00:00, 899.99it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "nu: 0.151 data predicted: 27 training_data predicted: 89\n",
      "nu: 0.291 data predicted: 28 training_data predicted: 89\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "prepare() missing 2 required positional arguments: 'vocab' and 'term_frequency'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9752/952227920.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[0mlda_target\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maudo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlda_modeling\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_topics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[1;31m#audo.lda_visualize_topics(type=\"clouds\", n_clouds=4)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m     \u001b[0maudo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlda_visualize_topics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"pyldavis\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\kantg\\Documents\\Uni\\AuDoLab\\AuDoLab\\AuDoLab.py\u001b[0m in \u001b[0;36mlda_visualize_topics\u001b[1;34m(self, save_name, lda_model, bow_corpus, dictionary, type, figsize, facecolor, width, height, background_color, topic, words, save, n_clouds)\u001b[0m\n\u001b[0;32m    384\u001b[0m             \u001b[0mwords\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    385\u001b[0m             \u001b[0msave\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 386\u001b[1;33m             \u001b[0mn_clouds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_clouds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    387\u001b[0m         )\n",
      "\u001b[1;32mc:\\Users\\kantg\\Documents\\Uni\\AuDoLab\\AuDoLab\\subclasses\\lda.py\u001b[0m in \u001b[0;36mvisualize_topics\u001b[1;34m(lda_model, bow_corpus, dictionary, save_name, type, figsize, facecolor, width, height, background_color, topic, words, save, n_clouds)\u001b[0m\n\u001b[0;32m    147\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"pyldavis\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m             visualization = pyLDAvis.prepare(\n\u001b[1;32m--> 149\u001b[1;33m                 \u001b[0mlda_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbow_corpus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msort_topics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    150\u001b[0m             )\n\u001b[0;32m    151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: prepare() missing 2 required positional arguments: 'vocab' and 'term_frequency'"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.0",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.0 64-bit ('AuDoLab': conda)"
  },
  "interpreter": {
   "hash": "897036928a98709e55f1a20e866055656ff707a6697846f8103ec94cffdc2255"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}